---
title: "Supplementary material for Dialect loss in the Russian North: modeling change across variables"
output:
  pdf_document:
    dev: cairo_pdf
  html_document:
    df_print: paged
---
This document contains code that reproduces figures and tables in the paper *Dialect loss in the Russian North: modeling change across variables*. See [README.md](https://github.com/LingConLab/Ustja_dialect_loss) for list of authors.

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
require("tidyverse")
require("lme4")
require("ggrepel")
```

## Preparation
### Initialization
```{r init}
save_figures <- FALSE
# set this to TRUE if you want figures to be saved

do_bootstrap <- FALSE
# set this to TRUE if you want to add bootstrapped confidence bands to figures
# WARNING: this is extremely slow
# Bootstrap will be used only for figures with confidence band,
# everywehere else regular confidence intervals will be used anyways.

bootstrap_iterations <- 1000
# ignored if do_bootstrap == FALSE

yearmin_band <- 1800
# minimum year for turning point calculations

yearmin <- 1920
# minimum year for plotting

yearmax <- 2000
# maximum year to consider


save_figures_to <- "figures"
# ignored if save_figures == FALSE

filenames <- c('var1_adj', 'var2_a-e', 'var3_sh', 'var4_prep', 
               'var5_refl1', 'var6_refl2', 
               'var7_ot', 'var8_tu', 'var10_nom', 'var11_e-i', 'var12_diss')

# this function convert filename to variable name
fn_to_vn <- function(fn) {
  str_replace(toupper(str_extract(fn, "(?<=_).+")), "-", "~")
}

variables <- fn_to_vn(filenames)

save_fig_if_needed <- function(filename) {
  if(save_figures) {
    ggsave(paste(save_figures_to, filename, sep="/"), device = cairo_pdf)
  }
}
```

### Data reading
```{r reading}
read_table <- function(var) {
  filename <- paste("tables", paste(var,'csv', sep='.'), sep="/")
  table <- read.csv(filename)
  table <- table[table$total > 0, ]
  # keep only meaningful rows
  
  table$prop <- table$cons / table$total
  # calculate proportions
  
  table$year20 <- table$year - 1920
  # new origin
  
  return(table)
}
```
Function `read_table` reads data that corresponds to a particular variable and make some pre-processing. For numerical stability, we use year 1920 as a new origin.

### Preprocessing

```{r preprocessing}
unaggregate <- function(table) {
  cons <- as.vector(table$cons)
  inn <- as.vector(table$inn)
  data <- data.frame(speaker=rep(table$speaker, 2), 
                     year = rep(table$year, 2), 
                     gender = rep(table$gender, 2), 
                     cons = rep(c(1, 0), each=nrow(table)), 
                     value = c(cons, inn))
  # make two replicas of the table
  # for the first replica, variable cons is set to 1
  # and in value column the number in table$cons is given
  # for the second replica, variable cons is set to 0
  # and in value column the number table$inn is given
  
  data <- data[rep(seq_len(nrow(data)), data$value), 1:4]
  # rep(seq_len(3), c(2, 4, 1)) --> 1 1 2 2 2 2 3
  # we duplicate each row of data the number of times given in $value

  data$year20 <- data$year - 1920
  return(data)
}
```
This function *unaggregates* data, i.e. in new table the row is one realization of a variable, either conservative or innovative.

### Model specification

```{r model}
reg <- function(data, bobyqa) {
  if (bobyqa) {
    return(glmer(cons ~ year20 + (1|speaker), data = data, family='binomial',
        control = glmerControl(optimizer = "bobyqa", nAGQ=10)))
  }
  else
  {
    return(glmer(cons ~ year20 + (1|speaker), data = data, family='binomial'))
  }
  
}
```
This is our regression model. For some cases we will use BOBYQA optimizer for numerical stability.

### Model evaluation
```{r bag}
bag <- function(table) {
  indicies = sample(1:nrow(table), replace = T, size=nrow(table))
  table[indicies,]
}
```
This function generates new sample by bagging (resampling with replacements). It will be used in bootstrap estimates for confidence intervals. Should be applied to initial (aggregated) data.

```{r confband}
# based on https://janhove.github.io/reporting/2017/05/12/visualising-models-2
# by Jan Vanhove
confband <- function(model) {
  vcov.m <- vcov(model)
  
  confband <- data.frame(year=seq(yearmin_band, yearmax, length.out = 10000))
  confband$year20 <- confband$year - 1920
  
  mm <- model.matrix(~ year20, confband)
  vars <- mm %*% vcov.m %*% t(mm)
  sds <- sqrt(diag(vars))
  z.val <- qnorm(1 - (1 - 0.95)/2)
  
  confband$pred_ <- predict(model, confband, type="link", re.form = NA)
  confband$lower_ <- confband$pred_ - z.val * sds
  confband$upper_ <- confband$pred_ + z.val * sds
  confband$pred <- plogis(confband$pred_)
  confband$lower <- plogis(confband$lower_)
  confband$upper <- plogis(confband$upper_)
  confband
}
```
This function finds confidence band around prediction curve.

```{r turning_gpoint}
turning_point_confint <- function(band) {
  c(lower=band[min(which(band$lower_<0)), "year"],
       upper=band[min(which(band$upper_<0)), "year"],
       estimate=band[min(which(band$pred_<0)), "year"])
}
```
This functions finds *turning point* (i.e. point of intersection of prediction curve with level probability=0.5) and its confidence interval.

```{r confint}
coeff_confint <- function(model) {
  est <- c(attributes(summary(model)$varcor$speaker)$stddev,
           summary(model)$coeff[,'Estimate'])
  # coefficient estimates
  
  conf <- confint.merMod(model, devtol=1e-6)
  # confidence intervals
  
  m <- cbind(est, conf)
  
  colnames(m) <- c('estimate', 'lower', 'upper')
  rownames(m) <- c('stddev', 'b0', 'b1')
  m <- rbind(m, p0=plogis(m['b0',]))
  return(m)
}
```
This function extracts confidence intervals for coefficients of the models: standard deviation of random effect (`stddev`), intercept (`b0`) and slope for `year20` (`b1`). It also calculates $p_0$'s (which are probabilities that corresponds to intercepts).

```{r bootstrap_confint}
bootstrap_confint <- function(table) {
  print("Doing bootstrap; this can be slow.") 
  bootstrap_predicts <- vector("list", bootstrap_iterations)
  
  for (i in 1:bootstrap_iterations) {
    print(i)
    bs_data <- unaggregate(bag(table))
    bootstrap_predicts[[i]] <- confband(reg(bs_data, bobyqa=FALSE))$pred
  }
  bs_confint <- t(sapply(transpose(bootstrap_predicts), 
                         function(x){quantile(unlist(x), 
                                              probs=c(0.05/2, 1-0.05/2), 
                                              na.rm=TRUE,
                                              type=8)}))
  colnames(bs_confint) <- c("bs_lower", "bs_upper")
  return(bs_confint)
}
```

```{r draw_fit}
  draw_fit_with_ribbon <- function(table, band) {
    fig <- ggplot() +
      geom_point(data=table, aes(x=year, y=prop, size=total), 
                 shape=21, fill='grey', color='black', alpha=0.6) +
      geom_line(size=1, alpha=0.8, aes(year, pred), data=band) +
      geom_ribbon(aes(ymin=lower, ymax=upper, x=year), 
                  alpha=0.3, 
                  data=band, 
                  color='steelblue2', 
                  fill='steelblue2') +
      theme_bw() +
      theme(plot.title = element_text(lineheight=1, size=12, 
                                      family="serif",
                                      margin=margin(0,0,10,0)), 
            axis.text=element_text(size=10, family="serif"), 
            axis.title=element_text(size=12, family="serif"),
            axis.title.y=element_text(margin=margin(0,10,0,0)), 
            axis.title.x=element_text(margin=margin(10,0,0,0)), 
            legend.text=element_text(size=10, family="serif"),
            legend.title=element_text(size=12, family="serif"),
            plot.margin=unit(c(0.4,0.15,0.15,0.15), 'cm')) +
      scale_x_continuous('year of birth', 
                         breaks=seq(yearmin, yearmax, 10), 
                         limits = c(yearmin, yearmax)) +
      scale_y_continuous('probability', 
                         breaks=seq(0,1,0.1), 
                         limits=c(0, 1)) +
      scale_size_continuous(range=c(1, 8)) +
      guides(size = guide_legend(title = 'number of\nobservations'))
    if (do_bootstrap) {
      fig <- fig + geom_ribbon(aes(ymin=bs_lower, ymax=bs_upper, x=year),
                               alpha=0.3, data=band, 
                               color='orange1', fill='orange1')
    }
    return(fig)
  }
```

## Main loop
Now we are ready to fit all models, plot figures and save confidence intervals.

```{r main_loop, results="hide", message=FALSE}
turning_points <- list()
coeffs <- list()
figs <- list()
models <- list()
anovas <- list()

for (fn in filenames) {
  print(paste("Processing", fn))
  table <- read_table(fn)
  data <- unaggregate(table)

  fit_re <- reg(data, bobyqa=(fn == 'var11_e-i'))
  # we use BOBYQA optimizer for variable var11_e-i in order
  # to achieve convergence for confidence intervals
  
  # summary(fit_re)
  band <- confband(fit_re)
  if (do_bootstrap) {
    band <- cbind(band, bootstrap_confint(table))
  }

  v <- fn_to_vn(fn)
  
  models[[v]] <- fit_re
  anovas[[v]] <- anova(fit_re, glmer(cons ~ 1 + (1|speaker),
                                     data=data,
                                     family='binomial'))['fit_re','Pr(>Chisq)']
  turning_points[[v]] <- turning_point_confint(band)
  coeffs[[v]] <- coeff_confint(fit_re)
  figs[[v]] <- draw_fit_with_ribbon(table, band)
  save_fig_if_needed(paste(fn, "pdf", sep="."))
}
```

## Plotting
### Figure 1
```{r figure1}
table <- read_table("var4_prep")

pair1 <- c('gvp1949', 'ffp1952')
pair2 <- c('ait1954', 'vkch1966')
pair3 <- c('mgb1949', 'ofsh1952')
speakers_to_point <- c(pair1, pair2, pair3)
table_compl <- table[!(table$speaker %in% speakers_to_point), ]
pair1_table <- table[table$speaker %in% pair1, ]
pair2_table <- table[table$speaker %in% pair2, ]
pair3_table <- table[table$speaker %in% pair3, ]

fig_threepairs <- ggplot(table_compl, aes(year, prop)) +
  geom_point(aes(x=year, y=prop, size=total), shape=21, 
             fill='grey', 
             color='black', alpha=0.6) +
  theme_bw() +
  geom_point(data=pair1_table, na.rm=TRUE, aes(x=year, y=prop, 
                                               size=total), 
             fill="white", shape=21) +
  geom_text_repel(data=pair1_table, aes(x=year, y=prop, label=speaker),
                  segment.color = "black",
                  size=3, alpha=0.8, box.padding = unit(0.3, 'lines'),
                  point.padding = unit(0.4, 'lines')) +
  geom_point(data=pair2_table, na.rm=TRUE, 
             aes(x=year, y=prop, size=total), 
             fill="white", shape=21) +
  geom_text_repel(data=pair2_table, aes(x=year, y=prop, label=speaker), 
                  size=3, alpha=0.8, box.padding = unit(0.3, 'lines'),
                  point.padding = unit(0.4, 'lines')) +
  geom_point(data=pair3_table, na.rm=TRUE, 
             aes(x=year, y=prop, size=total), fill="white", shape=21) +
  geom_text_repel(data=pair3_table, aes(x=year, y=prop, label=speaker), 
                  size=3, alpha=0.8, box.padding = unit(0.3, 'lines'),
                  point.padding = unit(0.4, 'lines')) +
  theme(plot.title = element_text(lineheight=1, size=12, 
                                  family="Liberation Serif",
                                  margin=margin(0,0,10,0)), 
        axis.text=element_text(size=10, family="Liberation Serif"), 
        #size of text
        axis.title=element_text(size=12, family="Liberation Serif"),
        axis.title.y=element_text(margin=margin(0,10,0,0)), 
        #space between axis and title!
        axis.title.x=element_text(margin=margin(10,0,0,0)), 
        #space between axis and title!
        legend.text=element_text(size=10, family="Liberation Serif"),
        legend.title=element_text(size=12, family="Liberation Serif"),
        plot.margin=unit(c(0.4,0.15,0.15,0.15), 'cm')) +
  scale_x_continuous('year of birth', breaks=seq(1920, 2000, 10)) +
  scale_y_continuous('proportion of dialectal realizations', 
                     breaks=seq(0,1,0.1), limits=c(0, 1)) +
  guides(size = guide_legend(title = 'number of\nobservations')) +
  scale_size_continuous(range=c(2,8))
fig_threepairs
save_fig_if_needed("figure1.pdf")
```

### Figure 2
```{r figure2, warning=FALSE}
figs$PREP
```
### Figure 3a
```{r figure3a, warning=FALSE}
figs$OT
```

### Figure 3b
```{r figure3b, warning=FALSE}
figs$ADJ
```

### Figures 4-6
```{r figures4_6}
draw_crossbars <- function(estimates) {
  p0 <- (as.data.frame(t(as.data.frame(estimates)))  
         %>% mutate(variable=variables) 
         %>% arrange(estimate))
  return(ggplot(p0) +
    geom_crossbar(aes(x=reorder(variable, estimate), 
                      y=estimate, ymin = lower, ymax = upper), 
                  size=0.4, width=0.4) +
    theme_bw() +
    theme(plot.title = element_text(lineheight=1, 
                                    size=12, 
                                    family="Liberation Serif",
                                    margin=margin(0,0,10,0)), 
          axis.text=element_text(size=10, family="Liberation Serif"), 
          #size of text
          axis.title=element_text(size=12, family="Liberation Serif"),
          axis.title.y=element_blank(), #space between axis and title!
          axis.title.x=element_blank(), #space between axis and title!
          legend.text=element_text(size=10, family="Liberation Serif"),
          legend.title=element_text(size=12, family="Liberation Serif"),
          plot.margin=unit(c(0.4,0.15,0.15,0.15), 'cm')) +
    scale_x_discrete('variable'))
}
```

#### Figure 4
```{r figure4}
draw_crossbars(lapply(coeffs, function(x) {x['p0',]})) +
  scale_y_continuous('probability',  breaks=seq(0, 1, 0.1))
save_fig_if_needed("figure4.pdf")
```

#### Figure 5
```{r figure5}
draw_crossbars(lapply(coeffs, function(x) {x['b1',]}))
save_fig_if_needed("figure5.pdf")
```

#### Figure 6

```{r figure6}
draw_crossbars(turning_points)
save_fig_if_needed("figure6.pdf")
```

## Appendix
In this section, we generate table and figures in the Appendix.

### Table 1

```{r appendix_table1}
as.data.frame(
  sapply(variables, function(var) {
    coeff <- coeffs[[var]]
    turpoint <- turning_points[[var]]
    c(
       b0_lower     = coeff['b0', 'lower'],
       b0           = coeff['b0', 'estimate'],
       b0_upper     = coeff['b0', 'upper'],
       p0_lower     = coeff['p0', 'lower'],
       p0           = coeff['p0', 'estimate'],
       p0_upper     = coeff['p0', 'upper'],
       b1_lower     = coeff['b1', 'lower'],
       b1           = coeff['b1', 'estimate'],
       b1_upper     = coeff['b1', 'upper'],
       variance     = summary(models[[var]])$varcor$speaker[1, 1],
       stddev_lower = coeff['stddev', 'lower'],
       stddev       = coeff['stddev', 'estimate'],
       stddev_upper = coeff['stddev', 'upper'],
       turning_point_lower = unname(turpoint['lower']),
       turning_point = unname(turpoint['estimate']),
       turning_point_upper = unname(turpoint['upper']),
       anova        = anovas[[var]]
     )
    })
)
```


### Figure 1
#### a)
```{r, warning=FALSE}
figs$ADJ
```

#### b)
```{r, warning=FALSE}
figs$`A~E`
```

#### c)
```{r, warning=FALSE}
figs$SH
```

#### d)
```{r, warning=FALSE}
figs$PREP
```

#### e)
```{r, warning=FALSE}
figs$REFL1
```

#### f)
```{r, warning=FALSE}
figs$REFL2
```

#### g)
```{r, warning=FALSE}
figs$OT
```

#### h)
```{r, warning=FALSE}
figs$TU
```

#### i)
```{r, warning=FALSE}
figs$NOM
```

#### j)
```{r, warning=FALSE}
figs$`E~I`
```

#### k)
```{r, warning=FALSE}
figs$DISS
```